{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Знакомство с линейным классификатором"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Как выглядит бинарный линейный классификатор? (Формула для отображения из множества объектов в множество классов.) \n",
    "\n",
    "$$a(x) = sign(w_0 + \\sum_{j=1}^{d}{w_j*x^j})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)  Что такое отступ алгоритма на объекте? Какие выводы можно сделать из знака отступа? \n",
    "\n",
    "Отступ относительно алгоритма классификации характеризует степень типичности объекта и уверенность в его принадлежности данному классу. Если отсутп отрицательный - алгоритм допускает ошиьку на данном объекте "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Как классификаторы вида a(x) = sign(< w,x > −w0) сводят к классификаторам вида a(x) = sign(< w,x >)?\n",
    "\n",
    "Путем добавления единичного признака к объектам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 4) Как выглядит запись функционала эмпирического риска через отступы? Какое значение он должен принимать для «наилучшего» алгоритма классификации?\n",
    " $ Q(w, X^l) = \\sum_{i=1}^l{[M_i(w)<0]} $\n",
    "\n",
    " Наилучшее значение функционала риска: 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 5) Если в функционале эмпирического риска (риск с пороговой функцией потерь) всюду написаны строгие неравенства (Mi < 0) можете ли вы сразу придумать параметр w для алгоритма классификации a(x) = sign(< w,x >), минимизирующий такой функционал?\n",
    " \n",
    " ${w} = 0$, так как в данном случае значение ответов будут всегду нулевыми, и ${Q} = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Запишите функционал аппроксимированного эмпирического риска, если выбрана функция потерь L(M)\n",
    " \n",
    " $ Q(a, X^l) = \\frac{1}{l}\\sum_{i=1}^l{L(a,x)} $\n",
    "  ,где $L(a,x)$ - функция потерь. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Что такое функция потерь, зачем она нужна? Как обычно выглядит ее график? \n",
    "\n",
    "Функция потерь — это неотрицательная функция $L (a, x)$, характеризующая величину ошибки алгоритма $a$ на объекте $x$. Если $L (a, x) = 0$,\n",
    "то ответ $a(x)$ называется корректным. График функции потерь "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 8) Приведите пример негладкой функции потерь. \n",
    " \n",
    " $L(a,x) = max(0,1-M)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 9) Что такое регуляризация? Какие регуляризаторы вы знаете?\n",
    " \n",
    "Регуляризация - добавление в функционал ошибки слегаемого, называемого резуляризатором.\n",
    "\n",
    "$l_1 = \\sum_{k=1}^m{|w_i|}$\n",
    "\n",
    "$l_2 = \\sum_{k=1}^m{(w_i)^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 10) Как связаны переобучение и обобщающая способность алгоритма? Как влияет регуляризация на обобщающую способность?\n",
    " \n",
    " При появлении факта переобучения обобщающая способность низкая. Использование регуляризатора позволяет снизить риск переобучения, тем самым повышая обобщающую способность алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) Как связаны острые минимумы функционала аппроксимированного эмпирического риска с проблемой переобучения?\n",
    "\n",
    "При обучении алгоритм минимизирует значение функционала риска по обучающей выборке, что не гарантирует высокого качества на тестовой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) Что делает регуляризация с аппроксимированным риском как функцией параметров алгоритма?\n",
    "\n",
    "Регуляризатор является неотрицательным слагаемым, в связи с этим он увеличивает значение риска, там самым вынуждая алгоритм не \"подгоняться\" под обучающую выборку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13) Для какого алгоритма классификации функционал аппроксимированного риска будет принимать большее значение на обучающей выборке: для построенного с регуляризацией или без нее? Почему?\n",
    "\n",
    "На функционале с регуляризатора, так как он будет учитывать значение весов модели. Если же убрать резуляризатор, то значение функционала упадет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14) Для какого алгоритма классификации функционал риска будет принимать большее значение на тестовой выборке:для построенного с оправдывающей себя регуляризацией или вообще без нее? Почему?\n",
    "\n",
    "Для построенного без регуляризации, так как такая модель переобучится под обучающую выборку, а на тестовой ее качетво(значение функционала) резко упадет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15) Что представляют собой метрики качества Accuracy, Precision и Recall?\n",
    " \n",
    "Accuracy - доля правильных ответов\n",
    "Precision - доля правильных положительных ответов\n",
    "Recall - доля правильно определенных положительных объектов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16) Что такое метрика качества AUC и ROC-кривая?\n",
    "\n",
    "$FPR = \\frac{FP}{FP + TN}$\n",
    "\n",
    "$TPR = \\frac{TP}{TP + FN}$\n",
    "\n",
    "ROC-кривая - кривая, отображающая зависимость значений FPR и TPR в засисимости от выбранного порога.\n",
    "AUC - площадь под $FPR ROC-кривой. Наилучшее значение:1. Если значение AUC<0.5, то классы необходимо поменять местами.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17) Как построить ROC-кривую (нужен алгоритм), если например, у вас есть правильные ответы к домашнему заданию про фамилии и ваши прогнозы?\n",
    "\n",
    "$a(x) = [b(x)>t] $ \n",
    "Перебирая значения параметра t, набираем значения TPR, FPR. По ним строим ROC-кривую."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) Вероятностный смысл регуляризаторов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Покажите, что регуляризатор в задаче линейной классификации имеет вероятностный смысл априорногораспределенияпараметровмоделей.Какиераспределениязадаютl1-регуляризатор и l2-регуляризатор?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3) SVM и максимизация разделяющей полосы "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Покажите, как получается условная оптимизационная задача, решаемая в SVM из соображений максимизации разделяющей полосы между классами. Можно отталкиваться от линейно разделимого случая, но итоговое выражение должно быть для общего. Как эта задача сводится к безусловной задаче оптимизации?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимизационная задача в случае линейно неразделимой выборки:\n",
    "\n",
    "$\\begin{cases}  \n",
    "{\\frac{1}{2}<w,w>+C\\sum_{i=1}^l\\xi_i \\rightarrow \\min_{w,w_0,\\xi}}\\\\\n",
    "{y_i(<w,x_i>-w_0)>=1-\\xi_i,   i = 1,..,l}\\\\\n",
    "{\\xi_i>=0, i=1,..,l}\n",
    "\\end{cases}$\n",
    "\n",
    "$\\xi_i$ - величина ошибки на объектах $x_i$\n",
    "\n",
    "$M_i = y_i(<w,x_i>-w_0)$\n",
    "\n",
    "${\\xi_i>=0}$, ${\\xi_i>=1 - M_i}$, Следовательно\n",
    "\n",
    "$\\sum(\\xi_i)\\rightarrow min$\n",
    "\n",
    "$Q(w, w_0) = \\sum_{i=1}^l(1-M_i(w, w_0))_++\\frac{1}{2C}||w||^2 \\rightarrow \\min_{w,w_0}$ - безусловная задача оптимизации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4) Kernel trick "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Придумайте ядро, которое позволит линейному классификатору с помощью Kernel Trick построить в исходном пространстве признаков разделяющую поверхность $x^2_1 + 2x_2^2 = 3$. Какой будет размерность спрямляющего пространства?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(x_1, x_2) -> (x_1^2, x_2^2, \\sqrt{2}x_1x_2)$\n",
    "\n",
    "$x^2_1 + 2x_2^2 = 3  ->  \\frac{z_1}{3}+\\frac{2z_2}{3} = 1$\n",
    "\n",
    "Размерность спрямляющего пространства:3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5) l1-регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Покажите с помощью теоремы Куна-Таккера, что ограничение l1-нормы вектора весов числом и добавление штрафа с его l1-нормой приводят к построению одного и того же алгоритма. Можно считать, что регуляризатор добавляется по существу, т.е. меняет итоговый ответ по сравнению с оптимизационной задачей без регуляризатора."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "добавление штрафа с l1-нормой:\n",
    "\n",
    "$Q = \\sum_{i=1}^l{(<x_i,w>-w_0)}+\\sum_{k=1}^m{|w_i|}$\n",
    "\n",
    "j-я компонента градиента:\n",
    "$\\frac{\\partial Q}{\\partial w_j} = \\sum_{i=1}^l{x_i^j} - \\lambda sign(w_j) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ограничение l1-нормы вектора весов числом:\n",
    "$\\begin{cases}\n",
    "{Q = \\sum_{i=1}^l{(<x_i,w>-w_0)}}\\\\\n",
    "{\\sum_{k=1}^m{|w_i|} <= H}\n",
    "\\end{cases}$\n",
    "\n",
    "по теореме Куна-Таккера ищем решение в виде уравнения:\n",
    "\n",
    "$\\bigtriangledown Q(w) - u\\bigtriangledown(H - \\sum_{k=1}^m{|w_i|}) = 0$\n",
    "\n",
    "при условии:\n",
    "$u\\geq 0$\n",
    "\n",
    "\n",
    "Получаем j-ю компоненту:\n",
    "\n",
    "$\\sum_{i=1}^l{x_i^j,} - u*sign(w_j)$\n",
    "\n",
    "Следовательно, $ u = \\lambda$, что и требовалось доказать.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6) Повторение: метрики качества "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Что представляют собой метрики качества Accuracy, Precision и Recall? \n",
    "2. Что такое метрика качества AUC и ROC-кривая? \n",
    "3. Как построить ROC-кривую (нужен алгоритм), если например, у вас есть правильные ответы к домашнему заданию про фамилии и ваши прогнозы?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)Accuracy - доля правильных ответов Precision - доля правильных положительных ответов Recall - доля правильно определенных положительных объектов\n",
    "\n",
    "2)$FPR = \\frac{FP}{FP + TN}$\n",
    "\n",
    "$TPR = \\frac{TP}{TP + FN}$\n",
    "\n",
    "ROC-кривая - кривая, отображающая зависимость значений FPR и TPR в засисимости от выбранного порога.\n",
    "AUC - площадь под $FPR ROC-кривой. Наилучшее значение:1. Если значение AUC<0.5, то классы необходимо поменять местами.\n",
    "\n",
    "\n",
    "3)$a(x) = [b(x)>t] $ \n",
    "Перебирая значения параметра t, набираем значения TPR, FPR. По ним строим ROC-кривую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
